{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9051f572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1ca007c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[1, 2, 3, 4, 5], [6, 7, 8, 9, 10]], columns=['A', 'B', 'C', 'D', 'E'], index=['row1', 'row2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3a45ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2eb9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b3466e",
   "metadata": {},
   "source": [
    "#### loading dataframes from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d08862c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = pd.read_csv('./warmup-data/coffee.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a77a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "194566b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_parquet('./data/results.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148041ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a25a32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_data = pd.read_excel('./data/olympics-data.xlsx',sheet_name='results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b489764",
   "metadata": {},
   "outputs": [],
   "source": [
    "olympics_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ce44a56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = pd.read_csv('./warmup-data/coffee.csv')\n",
    "results = pd.read_parquet('./data/results.parquet')\n",
    "bios = pd.read_csv('./data/bios.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466390c",
   "metadata": {},
   "source": [
    "#### Importing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca3f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.head() # to access the first 5 rows\n",
    "coffee.tail() # to access the last 5 rows\n",
    "coffee.sample(5) # to access 5 random rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b0217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coffee.loc[rows, columns] # to access specific rows and columns\n",
    "coffee.loc[5:8, ['Day', 'Coffee Type']] # to access specific rows and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "047ab826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# coffee.iloc[5:8, [0, 1]] # to access specific rows and columns by index\n",
    "coffee.iloc[5:8, [0, 1]] # to access specific rows and columns by index\n",
    "# iloc and loc is almost the same,\n",
    "# the only difference is that loc uses labels and iloc uses index positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dbd1c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.index = coffee['Day'] # to set the index of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3d8a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.loc['Monday':'Wednesday', 'Units Sold'] # to access specific rows and columns by index labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c922fb6",
   "metadata": {},
   "source": [
    "### Accessing data with pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f5178540",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.loc[1:3, 'Units Sold'] = 10 # to set specific values in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d62509",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dbb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.iat[0,0] # to access a specific cell by index position\n",
    "coffee.at[0, 'Coffee Type'] # to access a specific cell by index label\n",
    "# difference between iat and at is that iat uses index positions and at uses index labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6710f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298af033",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.sort_values(['Units Sold', 'Coffee Type'], ascending=[False, True]) # to sort the DataFrame by multiple columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306609f6",
   "metadata": {},
   "source": [
    "### Filtering data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f76aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad677dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios[bios['height_cm']>215][['name', 'height_cm']] # to filter rows based on a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee6ca6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also set multiple conditions using & and | operators\n",
    "bios[(bios['height_cm'] > 215) & (bios['weight_kg'] > 100)][['name', 'height_cm', 'weight_kg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0d5411",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios[bios['name'].str.contains('Hamza|patrick')][['name', 'height_cm', 'weight_kg']]\n",
    "# we can also use str.contains() to filter rows based on a string condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3523101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it is case-sensitive by default, but we can set the case parameter to False to make it case-insensitive\n",
    "bios[bios['name'].str.contains('Hamza|patrick', case=False)][['name', 'height_cm', 'weight_kg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a027bea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios[(bios['born_country'].isin(['USA', 'FRA', 'GBR'])) & (bios['name'].str.startswith('Keith'))][['name', 'born_country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eca404",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.query('born_country == \"PAK\"')[['name', 'born_country']] # to filter rows using query method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd9c420e",
   "metadata": {},
   "source": [
    "### Adding or removing coloums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0a42771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['Price'] = 4.99 # to add a new column with a constant value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7fe389",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c415e57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "14769623",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['new_price'] = np.where(coffee['Coffee Type']== 'Espresso', 5.99, 4.99) # to add a new column with a condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "974a21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.drop(columns=['Price'], inplace=True) # to remove a column from the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7ef07a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['revenue'] = coffee['Units Sold'] * coffee['new_price'] # to add a new column with a calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474593d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "92857e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee = coffee.rename(columns={'new_price': 'Price', 'revenue': 'Revenue'}) # to rename columns in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7002e6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new = bios.copy() # to create a copy of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14298a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new['first_name'] = bios_new['name'].str.split(' ').str[0] # to add a new column with the first name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5504f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new.query('first_name == \"Hamza\"')[['name', 'first_name']] # to filter rows based on the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "37e450b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new['born_datetime'] = pd.to_datetime(bios_new['born_date'])\n",
    "bios_new['born_year'] = bios_new['born_datetime'].dt.year # to extract the year from the datetime column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7292ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new[['name','born_year']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "b6e31089",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new.to_csv('./data/bios_new.csv', index=False) # to save the DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8e9dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios['height_category'] = bios['height_cm'].apply(lambda x: 'Tall' if x > 170 else 'Short') # to add a new column with a condition using apply\n",
    "bios[['name', 'height_cm', 'height_category']].head() # to access the new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8b69ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_athelete(row):\n",
    "    if row['weight_kg'] > 100:\n",
    "        return 'Heavyweight'\n",
    "    elif row['weight_kg'] < 50:\n",
    "        return 'Lightweight'\n",
    "    else:\n",
    "        return 'Middleweight'\n",
    "    \n",
    "bios['Category'] = bios.apply(categorize_athelete, axis=1) # to add a new column with a function using apply"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10a496",
   "metadata": {},
   "source": [
    "### Merging and concatinating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c46fb29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nocs = pd.read_csv('./data/noc_regions.csv') # to read a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1f7902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new = pd.merge(bios_new, nocs, left_on='born_country', right_on='NOC', how='left') # to merge two DataFrames on a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8c6690",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios_new.rename(columns={'region': 'born_country_full'}, inplace=True) # to rename a column in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77cd27dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = bios[bios['born_country'] == 'USA'].copy() # to filter rows and create a copy\n",
    "gbr = bios[bios['born_country'] == 'GBR'].copy() # to filter rows and create a copy\n",
    "pak = bios[bios['born_country'] == 'PAK'].copy() # to filter rows and create a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cf2cb407",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = pd.concat([usa, gbr, pak], ignore_index=True).copy() # to concatenate DataFrames and reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a826e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(results, bios , on='athlete_id', how='left') # to merge two DataFrames on a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "58a80063",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.loc[[0,1], 'Units Sold'] = np.nan # to set specific values in the DataFrame to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d32d9ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.fillna(coffee['Units Sold'].mean(), inplace=True) # to fill NaN values with the mean of the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7950395b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.loc[[0,2], 'Units Sold'] = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7bf3fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['Units Sold'].interpolate() # to fill NaN values using interpolation\n",
    "# interpolate() method fills NaN values using linear interpolation by default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb28239",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.dropna() # to drop rows with NaN values\n",
    "# warning: this will drop all rows with NaN values in any column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73c499a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['Units Sold'].notna() # to check if the values in the column are not NaN\n",
    "coffee['Units Sold'].isna()  # to check if the values in the column are NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e92fd5",
   "metadata": {},
   "source": [
    "### Aggregating data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3259ba3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.groupby(['Coffee Type']).agg({'Units Sold': 'sum'}) # to aggregate data by a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "85fcc06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot = coffee.pivot(columns='Coffee Type', index='Day', values='Units Sold') # to pivot the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8095e798",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.loc['Monday', 'Latte'] # to access a specific value in the pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00b87bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.sum() # to get the sum of each column in the pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe3f8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot.sum(axis=1) # to get the sum of each row in the pivot table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68303e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios['born_date'] = pd.to_datetime(bios['born_date']) # to convert a column to datetime format\n",
    "bios.groupby(bios['born_date'].dt.year)['name'].count().reset_index().sort_values('name', ascending=False).head(10) \n",
    "# to group by year and count the number of athletes born in each year"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bf5c01",
   "metadata": {},
   "source": [
    "### Advanced functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9046f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['yesterday_revenue'] = coffee['revenue'].shift(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a7a2e38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['pct_change'] = coffee['revenue']/ coffee['yesterday_revenue'] - 1 # to calculate the percentage change from the previous value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "7270cc65",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios['height_rank'] = bios['height_cm'].rank(ascending=False) # to rank the height column in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600b1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bios.sort_values(['height_rank', 'weight_kg']).sample(10)[['name','height_rank']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc12aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee.select_dtypes('float').cumsum().reset_index() \n",
    "# to calculate the cumulative sum of float columns and reset the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "6e290067",
   "metadata": {},
   "outputs": [],
   "source": [
    "coffee['cumulative_sum'] = coffee['revenue'].cumsum() # to calculate the cumulative sum of a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ff04d1a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lattee = coffee[coffee['Coffee Type'] == 'Latte'].copy() # to filter rows and create a copy\n",
    "lattee['3_day'] = lattee['Units Sold'].rolling(3).sum() # to calculate the rolling sum of the last 3 days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907567c9",
   "metadata": {},
   "source": [
    "### New functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b021a8a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.3'"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.__version__ # to check the version of pandas\n",
    "# currently mine one is 2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265b51a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are some new functionalities in pandas 2.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "207c9250",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_numpy = pd.read_csv('./data/results.csv') # to read a CSV file with numpy support\n",
    "results_arrow = pd.read_csv('./data/results.csv', engine='pyarrow', dtype_backend='pyarrow') \n",
    "# to read a CSV file with pyarrow support\n",
    "# some new functionalities include:\n",
    "# - Reading CSV files with numpy and pyarrow support\n",
    "# - Improved performance for large DataFrames\n",
    "# - Enhanced support for nullable integer and boolean data types\n",
    "# - New methods for DataFrame and Series objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5002a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_numpy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b532bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_arrow.info()# here we can see the new data types and performance improvements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
